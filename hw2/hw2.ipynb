{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the specified columns (1-indexed: 2nd, 4th, and 6th) from the CSV file\n",
    "data = np.loadtxt('your_file.csv', delimiter=',', skiprows=1, usecols=(1, 3, 5))\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data to extract meaningful information\n",
    "# Each row contains: [number of participants, average age of acquisition, frequency count]\n",
    "for row in data:\n",
    "    participants = int(row[0])\n",
    "    avg_age = row[1]\n",
    "    frequency = int(row[2])\n",
    "    print(f\"Participants: {participants}, Average Age of Acquisition: {avg_age}, Frequency: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0f301",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check the shape of the array\n",
    "print(\"Shape of the array:\", data.shape)\n",
    "\n",
    "# Check the data type of the array\n",
    "print(\"Data type of the array:\", data.dtype)\n",
    "\n",
    "# Calculate basic statistics\n",
    "print(\"Minimum value in each column:\", np.min(data, axis=0))\n",
    "print(\"Maximum value in each column:\", np.max(data, axis=0))\n",
    "print(\"Mean value in each column:\", np.mean(data, axis=0))\n",
    "print(\"Standard deviation in each column:\", np.std(data, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e04233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with NaN values\n",
    "filtered_data = data[~np.isnan(data).any(axis=1)]\n",
    "\n",
    "print(\"Filtered data (rows without NaN values):\")\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6957dc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Recalculate summary statistics for filtered data\n",
    "min_values = np.min(filtered_data, axis=0)\n",
    "max_values = np.max(filtered_data, axis=0)\n",
    "mean_values = np.mean(filtered_data, axis=0)\n",
    "std_dev_values = np.std(filtered_data, axis=0)\n",
    "\n",
    "# Print the summary statistics\n",
    "print(\"Summary Statistics for Filtered Data:\")\n",
    "print(f\"Minimum values: {min_values}\")\n",
    "print(f\"Maximum values: {max_values}\")\n",
    "print(f\"Mean values: {mean_values}\")\n",
    "print(f\"Standard deviation: {std_dev_values}\")\n",
    "\n",
    "# Check for potential surprises (e.g., unusually high/low values)\n",
    "threshold = 2 * std_dev_values  # Example threshold for anomalies\n",
    "anomalies = np.any((filtered_data < (mean_values - threshold)) | (filtered_data > (mean_values + threshold)), axis=0)\n",
    "\n",
    "print(\"\\nPotential anomalies detected in columns:\")\n",
    "for i, anomaly in enumerate(anomalies):\n",
    "    if anomaly:\n",
    "        print(f\"Column {i + 1} has potential anomalies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e952265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the last column of the array to turn raw frequencies into relative word frequencies\n",
    "filtered_data[:, -1] /= np.sum(filtered_data[:, -1])\n",
    "\n",
    "print(\"Normalized data (last column as relative frequencies):\")\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6c9ec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a smooth density estimate of the relative word frequencies\n",
    "sns.kdeplot(filtered_data[:, -1], fill=True)\n",
    "plt.title(\"Density Estimate of Relative Word Frequencies\")\n",
    "plt.xlabel(\"Relative Word Frequency\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the logarithms of the raw frequencies\n",
    "log_frequencies = np.log(filtered_data[:, -1])\n",
    "sns.kdeplot(log_frequencies, fill=True)\n",
    "plt.title(\"Density Estimate of Logarithms of Raw Frequencies\")\n",
    "plt.xlabel(\"Logarithm of Raw Frequency\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Observations\n",
    "print(\"Notice if the logarithmic plot shows unusual clustering or gaps, which might indicate issues in the data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270d2483-61f9-4940-b666-7434079dc8b8",
   "metadata": {},
   "source": [
    "# Unicode Character Extraction and Filtering\n",
    "This notebook extracts Unicode characters from a file and filters words that contain only Albanian letters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ca591-db7a-47e6-a970-266f152884f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb426fc-f863-48a4-99fb-0eaf44972f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Unicode characters: {'ό', 'ु', 'க', 'ξ', 'ხ', 'ë', 'µ', '抜', 'ҫ', '¼', '門', 'Ч', '→', 'ν', '血', 'ъ', 'z', '安', '£', '船', 'ρ', '堂', '苦', '太', 'å', 'ح', 'ध', 'ベ', '宮', 'ل', '方', 'ﻦ', 'び', 'm', '心', 'v', '2', '藤', 'כ', '민', 'タ', 'э', '忍', '智', '雀', '5', 'B', 'ˁ', 'ÿ', 'n', '不', '†', 'ä', '男', 'ル', '음', 'マ', ';', '月', 'h', 'ἀ', 'ˇ', 'چ', 'خ', 'ං', 'М', '≡', 'р', '白', 'Ј', ' ', 'Ω', 'W', '越', '?', 'Ή', '空', '界', 'Í', 'ʾ', 'º', 'ṣ', 'я', 'シ', 'ǔ', '⌂', '騎', 'Β', 'श', '，', '六', '\\u200e', 'Z', 'ḱ', 'प', '木', '́', '者', 'S', 'ზ', 'н', 't', 'ū', 'ा', 'ِ', '(', '6', 'Ø', 'д', '無', '₆', '世', 'ク', 'ạ', 'V', 'ə', 'и', 'أ', '정', 'А', '½', 'ა', 'r', '*', '省', 'し', 'ć', 'ã', '郑', 'В', 'П', 'c', '>', 'й', '<', 'ц', '林', '°', '鍵', 'レ', '錦', 'გ', 'M', 'Ά', 'ê', 'т', 'ᾄ', '表', 'Ҫ', '„', '⟩', '英', '/', 'g', '…', '्', '•', '怪', 'ع', 'א', '慈', '仲', 'Đ', 'þ', 'ق', 'š', 'o', 'ι', '和', 'Å', 'ج', 'π', 'ð', 'र', '本', '鯉', 'ż', '子', '新', 'Q', 'q', '今', '’', 'Î', '.', '校', 'じ', 'С', 'ூ', '0', '下', 'щ', '赋', 'à', 'ニ', 'Ș', 'ὴ', '№', 'ḥ', 'J', 'ς', 'ő', 'ῳ', 'म', 'ﻭ', '塔', 'パ', '€', 'ø', 'ñ', '珍', 'σ', '相', 'す', '♋', 'س', 'θ', 'ύ', '議', 'Ś', '′', 'ّ', 'Æ', 'ṇ', 'ö', 'έ', 'ҡ', 'у', 'È', 'Σ', '学', '්', 'Ú', 'ŷ', '!', '雷', 'ୁ', '¤', '门', '훈', '浄', 'î', 'ட', '京', 'N', '円', 'ἠ', '官', 'ي', 'Φ', 'T', '代', '十', 'ن', '餅', 'Þ', '清', 'ן', '்', '絵', 'Ḥ', '限', 'ּ', 'ṭ', '魔', '仏', '遁', '\"', 'Ẓ', 'ァ', '한', 'Г', '口', '段', '夫', 'ﬁ', 'Ζ', 'Ἀ', '秀', '»', '忠', '仁', 'ロ', '恵', 'ợ', '紅', '輪', 'â', 'ː', 'گ', 'x', 'ت', 'ḏ', 'Ѓ', '切', 'ф', '四', '正', 'ṃ', 'Ï', '鄭', 'ă', '復', '政', '話', 'ش', 'ﻳ', '$', 'ォ', '≠', 'ע', 'Ἱ', '次', 'ग', 'י', 'Λ', 'ấ', 'ェ', 'в', '（', 'п', '³', 'O', 'К', 'ἐ', 'و', 'м', '板', 'A', '奈', '坊', '☉', 'О', 'Ṣ', '敏', 'غ', '生', '“', '冷', '준', 'ϊ', 'ୀ', 'る', 'ř', '石', 'Π', 'ß', '∟', 'ʿ', 'ක', 'ɛ', 'イ', 'İ', 'ț', 'ת', 'フ', 'あ', 'í', 'ʔ', '´', 'ἴ', 'け', 'ư', '密', '蓮', 'ோ', 'ʊ', 'ь', 'Ν', '座', 'ソ', 'ķ', '佛', 'ல', 'ギ', '武', 'ī', '~', '₂', 'Ç', '蜂', 'ș', '写', 'ک', 'ძ', 'Ȅ', 'ы', '˚', 'с', '・', '猛', '嘯', 'ȳ', 'ḍ', 'ē', 'Ë', '―', 'ο', 'ブ', '公', '∼', '講', 'ǐ', 'κ', '遊', 'ツ', 'У', '%', 'ш', 'ж', 'ā', '⁄', 'ά', '龙', '面', 'а', 'ą', '蛍', '盟', '圓', 'ү', 'Č', '須', 'л', 'ल', '義', 'ὑ', 'Τ', 'ி', 'უ', 'о', 'ラ', '領', 'ஆ', '看', 'ņ', 'َ', 'Μ', 'ε', 'Ž', 'Γ', 'D', '語', '⃗', '¾', '幸', 'k', 'د', '李', 'Ε', '》', 'ầ', '狂', '¬', '先', 'E', '8', '厚', 'ġ', 'ῦ', 'カ', 'ん', 'დ', 'ϝ', 'ז', '歌', 'х', 'ῖ', 'Ḫ', 'ō', '婚', 'I', 'C', 'ე', 'ر', 'á', 'ṅ', 'Α', 'ò', '獄', 'χ', '南', 'L', '地', 'Κ', 'م', 'Е', '日', 'न', 'ì', '星', '7', 'נ', 'ड', '野', '禅', '結', 'ھ', 'ů', '術', '手', 'Y', 'ャ', '眼', 'ه', '肇', 'φ', '«', '二', '繁', '蒜', 'ბ', 'ί', 'ල', 'ჯ', 'ك', 'ا', 'è', '\\u200b', '字', 'მ', '顧', 'ῆ', '狩', 'ପ', 'ş', '鞭', 'ス', '居', 'Ā', 'ド', 'Э', 'г', 'Ţ', 'Ф', 'ï', 'ン', '김', '卸', '×', '≈', 'ך', 'ש', 'Ρ', '″', '`', '一', 'к', 'ὄ', '9', 'ゅ', 'Ł', 'ή', 'y', 'ű', '\\uf0b0', 'ċ', '飛', 'ダ', ',', 'ἶ', 'Ē', '里', 'ز', 'ـ', 'Š', 'ü', 'ま', '嵐', '̠', '号', 'τ', 'ĭ', 'Р', '俳', '流', 'É', '§', 'a', 'ḫ', 'स', 'b', 'γ', 'λ', 'ர', '±', 'ئ', 'μ', 'Θ', 'ର', 'ś', 'η', 'i', 'd', 'ὶ', '栗', 'த', 'ී', 'ف', '眠', 'ා', '井', '福', '伝', '—', 'ł', 'ý', 'ィ', '남', '部', 'ַ', '淀', 'ё', 'Ё', 'ʼ', 'ლ', 'ი', '¥', 'H', 'Χ', '郎', '™', 'ψ', 'ფ', 'ض', 'ω', 'α', 'ო', 'F', 'w', 'რ', 'ب', 'j', 'æ', 'K', 'ण', '−', ':', 'β', '士', 'ண', 'œ', '取', 'ヘ', 'ב', '话', '赤', '社', '‘', 'ň', '良', 'ா', 'ʏ', '虚', '獣', '団', 'Ä', '\\n', '글', 'f', '≥', '山', '⟨', '大', 'Ö', '純', 'Ι', 'U', 'Д', 'ź', '式', '《', '舞', '1', 'ě', 'ž', '雨', '女', 'Ō', 'შ', '北', '腹', '杀', 'の', '古', 'プ', '酌', '健', 'ó', 'ç', 'Б', 'ء', '人', '²', 'வ', 'ム', 'ط', 'ô', '令', 'Ż', 'サ', 'Δ', 'é', '美', 'ј', 'ボ', '3', 'ď', 'ს', '修', 'ो', 'り', 'ו', 'ч', 'ワ', '擺', '鬼', 'ズ', 'リ', 'ţ', 'ר', '三', '金', 'ー', 'G', '‰', 'ἵ', '-', '迪', 'テ', 'ة', 'u', 'ę', '説', '₄', 'б', 'ص', 'ვ', '王', 'ĝ', 'υ', 'Œ', '邸', '会', '興', 'ζ', 'ि', '屠', '砕', 'δ', 'ṯ', '宗', ')', 'l', 'バ', '帝', '）', '房', '室', 'ė', '衫', '‐', 'p', '‖', '\\u2009', '上', 'ń', 'Á', '4', '¢', '丸', 'ශ', 'ガ', '+', '天', '₈', 'č', '札', '羽', '‑', 'õ', '伎', '粋', '為', 'ú', 'P', '文', '·', '揚', 'đ', '敢', '道', 'Т', 'מ', 'ה', 'ώ', 'ヴ', 'Ć', 'ර', '‚', '–', '吳', 'ッ', 'त', 'û', '皇', '松', '浮', 'И', '株', '追', '∪', 'グ', '&', 'Х', '雄', 'ჩ', 'ウ', 'Ş', 'ʃ', 'Ü', '廻', 'з', 'い', 'ひ', 'ı', 'ù', 'X', '宫', '碓', \"'\", '”', 'ğ', 'R', '鯱', 's', 'ƒ', 'e', 'е', 'ˤ', '川', 'Ħ'}\n"
     ]
    }
   ],
   "source": [
    "# Load the file and extract unique Unicode characters\n",
    "def extract_unicode_chars(filename):\n",
    "    with open(filename, encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return set(text)\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"sq-sample.txt\"\n",
    "unicode_chars = extract_unicode_chars(file_path)\n",
    "print(\"Unique Unicode characters:\", unicode_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce82355-9afe-493b-b112-e84608477c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the allowed Albanian letters (both uppercase and lowercase)\n",
    "allowed_chars = set(\"abcçdeëfghijklmnopqrstuvxyzABCÇDEËFGHIJKLMNOPQRSTUVXYZ\")\n",
    "\n",
    "def is_albanian(word):\n",
    "    return all(char in allowed_chars for char in word)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f72a8d-7228-4fba-bbb8-68d048d9de22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Albanian words: ['shtëpi', 'hello', 'tungjatjeta']\n"
     ]
    }
   ],
   "source": [
    "# Define the allowed Albanian letters (both uppercase and lowercase)\n",
    "allowed_chars = set(\"abcçdeëfghijklmnopqrstuvxyzABCÇDEËFGHIJKLMNOPQRSTUVXYZ\")\n",
    "\n",
    "def is_albanian(word):\n",
    "    return all(char in allowed_chars for char in word)\n",
    "\n",
    "    # Example usage:\n",
    "test_words = [\"shtëpi\", \"hello\", \"tungjatjeta\", \"12345\",\"şörle\"]\n",
    "filtered_words = [word for word in test_words if is_albanian(word)]\n",
    "print(\"Filtered Albanian words:\", filtered_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96eb2fe1-f9f6-42ad-aac8-1a0c1c9bbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "# Load the file\n",
    "def load_text(filename):\n",
    "    with open(filename, encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "file_path = \"sq-sample.txt\"\n",
    "text = load_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e105d7-6f90-4e9d-9bb7-f253d8f4d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into sentences\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "# Shuffle the sentences randomly\n",
    "random.shuffle(sentences)\n",
    "\n",
    "# Reconstruct scrambled text\n",
    "scrambled_text = ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96bd02c1-446c-4ab3-b208-fbbfeb955ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization: split at whitespaces and convert to lowercase\n",
    "tokens = re.split(r'\\s+', scrambled_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6176fd6d-dc6c-41f9-8814-970b3386cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and digits\n",
    "tokens_cleaned = [re.sub(r'[^a-zA-ZçÇëË]', '', token) for token in tokens if token.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94606b75-1d56-4bb7-9721-d1e29f036f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Albanian tokens: 1916075\n"
     ]
    }
   ],
   "source": [
    "# Filter words using is_albanian function\n",
    "albanian_tokens = [word for word in tokens_cleaned if is_albanian(word)]\n",
    "\n",
    "print(f\"Total Albanian tokens: {len(albanian_tokens)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d6465d-a873-4609-b3c6-2f75efe8c5d7",
   "metadata": {},
   "source": [
    "# Print each Albanian token one by one\n",
    "for token in albanian_tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07555ab1-1c0e-41c6-ab71-89a4c1c7415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens saved to albanian_tokens.txt\n"
     ]
    }
   ],
   "source": [
    "# Save tokens to a text file\n",
    "with open(\"albanian_tokens.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for token in albanian_tokens:\n",
    "        file.write(token + \"\\n\")\n",
    "\n",
    "print(\"Tokens saved to albanian_tokens.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c448eb23-8d2e-49d3-92ed-913637811d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens saved to albanian_tokens.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Save tokens to a CSV file\n",
    "with open(\"albanian_tokens.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Token\"])  # Add a header\n",
    "    for token in albanian_tokens:\n",
    "        writer.writerow([token])\n",
    "\n",
    "print(\"Tokens saved to albanian_tokens.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c003fe-34b0-4014-bd7a-7e63bb29c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Split into two roughly equal parts\n",
    "midpoint = len(albanian_tokens) // 2\n",
    "subcorpus1 = albanian_tokens[:midpoint]\n",
    "subcorpus2 = albanian_tokens[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5fd337-7727-425c-bf26-d6a87ea2a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency counters\n",
    "counter1 = Counter(subcorpus1)\n",
    "counter2 = Counter(subcorpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6b628b-7e22-4220-80bf-943232f437c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-50 most common words in Subcorpus 1:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'counter1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTop-50 most common words in Subcorpus 1:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcounter1\u001b[49m.most_common(\u001b[32m50\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTop-50 most common words in Subcorpus 2:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(counter2.most_common(\u001b[32m50\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'counter1' is not defined"
     ]
    }
   ],
   "source": [
    "# Print top-50 most common words in each subcorpus\n",
    "\n",
    "print(\"Top-50 most common words in Subcorpus 1:\")\n",
    "print(counter1.most_common(50))\n",
    "\n",
    "print(\"\\nTop-50 most common words in Subcorpus 2:\")\n",
    "print(counter2.most_common(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63710448-675b-45da-b8d6-ce5fd2bb3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top-50 most common words in each subcorpus one by one\n",
    "print(\"Top-50 most common words in Subcorpus 1:\")\n",
    "print(counter1.most_common(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe030b-03a9-4da9-9fbe-3579aa1b8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop-50 most common words in Subcorpus 2:\")\n",
    "print(counter2.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a83e6-0bc7-408c-af9c-0e537d2fc434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words unique to each subcorpus\n",
    "unique_to_1 = set(counter1.keys()) - set(counter2.keys())\n",
    "unique_to_2 = set(counter2.keys()) - set(counter1.keys())\n",
    "\n",
    "print(f\"\\nWords unique to Subcorpus 1: {unique_to_1}\")\n",
    "print(f\"Words unique to Subcorpus 2: {unique_to_2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
